{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL-Earthquake-Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [1. Introduction](#section1)\n",
    "* [2. Initial Setup](#section2)\n",
    "* [3. Training Set](#section3)\n",
    "* [4. Test Set](#section4)\n",
    "* [5. Models](#section5)\n",
    "    * [5.1 Correlations](#section5.1)\n",
    "    * [5.2 Spectrogram](#section5.2)\n",
    "    * [5.3 Fourier Transform per Sampling Sequence of 4096 measurements](#section5.3)\n",
    "    * [5.4 Wavelets Transform per Sampling Sequence of 4096 measurements](#section5.4)\n",
    "        * [5.4.1. Continous Wavelet Transf](#section5.4.1)\n",
    "        * [5.4.2. Discrete Wavelet Transform](#section5.4.2)\n",
    "* [6. Evaluation](#section6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from scipy import fftpack\n",
    "\n",
    "from os import listdir\n",
    "print(listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nrows = !wc -l ../input/train.csv\n",
    "train_nrows_val = int(train_nrows[0].split()[0])\n",
    "print('train.csv contains {:,} rows'.format(train_nrows_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../input/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = !head -n1 ../input/train.csv\n",
    "print(column_names[0].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = pd.read_csv('../input/train.csv', skiprows = 0, nrows=100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}) #use chunksize to iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df_with_preset_precision(df, precision):\n",
    "    curr_precision = pd.get_option(\"display.precision\")\n",
    "    pd.set_option(\"display.precision\", precision)\n",
    "    display(df)\n",
    "    pd.set_option(\"display.precision\", curr_precision)\n",
    "    \n",
    "display_df_with_preset_precision(df_train_sample.head(), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep minimal mem footprint \n",
    "try:\n",
    "    del(df_train_sample)    \n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_train_iter)    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "df_train_iter = pd.read_csv('../input/train.csv', chunksize=train_nrows_val//100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},iterator=True)\n",
    "\n",
    "df_after_jumping_up_points = pd.DataFrame()\n",
    "for df in df_train_iter:\n",
    "    df['diff_in_time_to_failure']=df['time_to_failure'].diff()\n",
    "    df_jumps = df.loc[(df['diff_in_time_to_failure'] > 0)]\n",
    "    #display(df_jumps)\n",
    "    df_after_jumping_up_points=df_after_jumping_up_points.append(df_jumps)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_after_jumping_up_points.shape)\n",
    "df_after_jumping_up_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_train_iter)    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "df_train_iter = pd.read_csv('../input/train.csv', chunksize=train_nrows_val//100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},iterator=True) #use chunksize to iterate\n",
    "df_before_jumping_up_points = pd.DataFrame()\n",
    "for df in df_train_iter:\n",
    "    if len(df.index.intersection(df_after_jumping_up_points.index-1)) > 0:\n",
    "        try:\n",
    "            df_before_jumping_up_points=df_before_jumping_up_points.append(df.loc[df.index.intersection(df_after_jumping_up_points.index-1),:])\n",
    "        except KeyError:\n",
    "            print('KeyError')\n",
    "            pass\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_before_jumping_up_points.shape)\n",
    "df_before_jumping_up_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "try:\n",
    "    del(df_train_tail)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_train_tail = pd.read_csv('../input/train.csv', skiprows = train_nrows_val-100000, iterator=False, names=column_names[0].split(','))\n",
    "df_train_tail['acoustic_data'] = df_train_tail['acoustic_data'].astype(np.int16)\n",
    "df_train_tail['time_to_failure'] = df_train_tail['time_to_failure'].astype(np.float64)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tail.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps in ttf:\n",
    "#ttf steps width is 4097 for the last section:\n",
    "#df_train_tail.tail(4097)['time_to_failure'].plot();\n",
    "df_train_tail.tail(20000)['time_to_failure'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "try:\n",
    "    del(df_train_head)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_train_head = pd.read_csv('../input/train.csv', skiprows = 0, nrows = 100000, iterator=False)\n",
    "\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttf steps width is 4096 for the first section:\n",
    "#df_train_head.head(4096)['time_to_failure'].plot();\n",
    "#df_train_head.head(20000)['time_to_failure'].plot();\n",
    "\n",
    "df_train_head.head(20000)[8192:8192+4096]['time_to_failure'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_train_head.head(20000)[8192:8192+4095]['time_to_failure'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "set(df_train_head.head(2000000)['time_to_failure'].diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What these steps in ttf mean? <br>\n",
    "Options: \n",
    "* 1. we are given not continuos in time sequencies (each 4096 samples) of acustic data. \n",
    "* 2. the sequences of the acustic data are continuous in time but ttf represent changing steps/jumps/phases in the state of the material\n",
    "\n",
    "The first option is more probable as it is unlikely that the changes in the phase states of the material will take place with such ideal periodicity. Then, time/frequency characteristics of the acustic_data should be considered taking into acount that the data is not continous in time. \n",
    "\n",
    "We assume that samples of the signal are taken each $10^{-3}$ time units (sec?/usec?) and each sample is a sequence of 4096 measurements taken each $10^{-9}$ time units. So, the length of the entire signal sample is $4.096\\times10^{-6}$ time units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ranges = [(ent[0],ent[1]) for ent in zip([0]+list(df_after_jumping_up_points.index)[:-1],list(df_before_jumping_up_points.index))]\n",
    "index_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths =np.array([ent[1]-ent[0] for ent in zip([0]+list(df_before_jumping_up_points.index)[:-1],list(df_before_jumping_up_points.index))])\n",
    "train_set_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index = 3 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15000\n",
    "window_offset = -window_size\n",
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "print(df_sample.index)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False)\n",
    "fig.set_size_inches(32,4)\n",
    "df_sample['acoustic_data'].plot(ax=axs[0]);\n",
    "#plt.show()\n",
    "df_sample['time_to_failure'].plot(ax=axs[1]);\n",
    "#plt.show()\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 16 train sequences. We may use multiple ways to separate them into train and validation groups. This way we will be able to efficiently utilize the training data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_to_failure_points = pd.read_csv('../input/train.csv', skiprows = 0, nrows= 1, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})['time_to_failure'].append(df_after_jumping_up_points['time_to_failure'])\n",
    "max_time_to_failure_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_to_failure_points.values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decline_angle_tangents = np.array([ent[0]/ent[1] for ent in zip(max_time_to_failure_points.values[:-1], max_time_to_failure_points.index[1:])])\n",
    "print(decline_angle_tangents.mean())\n",
    "print(decline_angle_tangents.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep minimal mem footprint \n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## 4. Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seg_files = listdir(\"../input/test\")\n",
    "test_seg_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -l ../input/test | wc -l\n",
    "len(test_seg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(\"../input/test\",test_seg_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l {os.path.join(\"../input/test\",test_seg_files[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {os.path.join(\"../input/test\",test_seg_files[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_seg_by_index(idx):\n",
    "    df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[idx]), dtype={'acoustic_data': np.int16})\n",
    "    df_test_seg['acoustic_data'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_test_seg_by_index, idx=widgets.IntSlider(min=0,max=len(test_seg_files)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#all seg files have the same length: 150,000 samples\n",
    "seg_files_lengths = !for filename in ../input/test/*; do wc -l $filename; done\n",
    "{ent.split(' ')[0] for ent in seg_files_lengths}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## 5. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following:\n",
    "* 1. investigate train sequences in parallel with window of variable size:  15000 or smaller\n",
    " * 1.1 normalize to the same process development speed; (with_time_to_failure plots)\n",
    " * 1.2 present the acustic_data in a form of mean plus delta from mean, then delta from mean present by its mean and delta from its mean etc. \n",
    "* 2. remove constant bias in train and in test\n",
    "* 3. simple MSE alignment \n",
    "* 4. simple maximaize dot product\n",
    "* 5. fourier (fft)\n",
    "* 6. short-time fourier (time frequency domain)\n",
    "* 7. wavelets (time frequency domain)\n",
    "* 8. voice spectrogrum; what is we are already given a spectorgrum (or other type of transform) but not the original signal? \n",
    "* 9. try to use notebooks used for the detection of gravitation waves\n",
    "* 10. xgboost\n",
    "* 11. try to extract a \"coherent\" signal and to remove the noise in the training data sequences \n",
    "* 12. set evaluation criterion\n",
    "* 13. try to accelerate the process using pytorch (on gpu) for matrix and vector operations\n",
    "* 14. try Fully Connected NN\n",
    "* 14. try CNNs\n",
    "* 15. try RNNs/LSTMs\n",
    "* 16. try exponential or other smoothing to reduce noise \n",
    "* 17. try considering 4096 samples as 64 x 64 image\n",
    "* 18. try averaging over all 16 training sequences - (in time or frequencey space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.1'></a>\n",
    "### 5.1. Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "range_index=0 #first training sequence is the shortest one\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False)\n",
    "fig.set_size_inches(32,4)\n",
    "df_sample['acoustic_data'].plot(ax=axs[0]);\n",
    "#plt.show()\n",
    "print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))\n",
    "df_sample['time_to_failure'].plot(ax=axs[1]);\n",
    "#plt.show()\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['time_to_failure'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to find points of maximum cross-correlation between the segment and the training sequence<br>\n",
    "To save time, the correlation should be calculated efficiently - this means do not implement it by yourself in python. We need to find best implementation of the correlation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = (df_sample['acoustic_data']-df_sample['acoustic_data'].mean()).values\n",
    "train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[0]), dtype={'acoustic_data': np.int16})\n",
    "df_test_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg['acoustic_data'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = (df_test_seg['acoustic_data']-df_test_seg['acoustic_data'].mean()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_corr = signal.correlate(np.square(train_values), np.square(test_values),mode='valid', #full, valid, same\n",
    "                               method='fft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(signal_corr).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_with_test_seg_idx(idx):\n",
    "    df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[idx]), dtype={'acoustic_data': np.int16})\n",
    "    test_values = (df_test_seg['acoustic_data']-df_test_seg['acoustic_data'].mean()).values\n",
    "    signal_corr = signal.correlate(np.square(train_values), np.square(test_values),mode='same', method='fft')\n",
    "    pd.DataFrame(signal_corr).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(correlation_with_test_seg_idx, idx=widgets.IntSlider(min=0,max=len(test_seg_files)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = timeit.default_timer()\n",
    "#np_corr = np.correlate(df_sample['acoustic_data'].values, df_test_seg['acoustic_data'].values)\n",
    "#print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))    \n",
    "#this takes too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.2'></a>\n",
    "### 5.2 Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1024\n",
    "N = 1024\n",
    "freqs, times, Sx = signal.spectrogram(df_test_seg['acoustic_data'].values, fs=1, window='hanning',\n",
    "                                      nperseg=N, noverlap=M - 100,\n",
    "                                      detrend=False, scaling='spectrum')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(4.8, 2.4))\n",
    "ax.pcolormesh(times, freqs / 1000, 10 * np.log10(Sx), cmap='viridis')\n",
    "ax.set_ylabel('Frequency [kHz]')\n",
    "ax.set_xlabel('Time [s]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, t, Sxx = spectrogram(df_test_seg['acoustic_data'].values)\n",
    "plt.pcolormesh(t, f, 10 * np.log10(Sxx))\n",
    "plt.show()\n",
    "plt.plot(Sxx)\n",
    "#plt.ylabel('Frequency [Hz]')\n",
    "#plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util\n",
    "\n",
    "M = 1024\n",
    "\n",
    "slices = util.view_as_windows(df_test_seg['acoustic_data'].values, window_shape=(M,), step=100)\n",
    "print(f'data shape: {df_test_seg[\"acoustic_data\"].values.shape}, Sliced data shape: {slices.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = np.hanning(M + 1)[:-1]\n",
    "slices = slices * win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = slices.T\n",
    "print('Shape of `slices`:', slices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = np.fft.fft(slices, axis=0)[:M // 2 + 1:-1]\n",
    "spectrum = np.abs(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=df_test_seg['acoustic_data'].values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(4.8, 2.4))\n",
    "\n",
    "S = np.abs(spectrum)\n",
    "S = 20 * np.log10(S / np.max(S))\n",
    "\n",
    "ax.imshow(S, origin='lower', cmap='viridis',\n",
    "          extent=(0, L, 0, rate / 2 / 1000))\n",
    "ax.axis('tight')\n",
    "ax.set_ylabel('Frequency [kHz]')\n",
    "ax.set_xlabel('Time [s]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_seg['acoustic_data'].values\n",
    "# Number of sample points\n",
    "#N = 600\n",
    "# sample spacing\n",
    "#T = 1.0 / 800.0\n",
    "#x = np.linspace(0.0, N*T, N)\n",
    "#y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n",
    "\n",
    "#yf = fft(y)\n",
    "yf = fftpack.fft(df_test_seg['acoustic_data'].values)\n",
    "#df_test_seg['acoustic_data'].values\n",
    "\n",
    "#xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "#plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "plt.plot(np.abs(yf))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.3'></a>\n",
    "## 5.3 Fourier Transform per Sampling Sequence of 4096 measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.fft.html <br>\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/fftpack.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index=12 #first training sequence is the shortest one\n",
    "sequence_length = 4096\n",
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "print(df_sample.shape[0]/sequence_length)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN (Bias) is removed \n",
    "#sequence_idx = 2 #10845\n",
    "avg_len=2\n",
    "sequence_offset = 0\n",
    "def show_frame_and_fft(sequence_idx):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=6, sharex=False)\n",
    "\n",
    "    print(df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length].shape)\n",
    "    df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['time_to_failure'].plot(ax=axs[0]);\n",
    "    \n",
    "    acustic_data_series = df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data']\n",
    "    (acustic_data_series - acustic_data_series.mean()).plot(ax=axs[1]);\n",
    "    #df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data'].plot(ax=axs[1]);\n",
    "\n",
    "    fig.set_size_inches(32,4)\n",
    "    \n",
    "    acustic_data_ft = fftpack.fft(acustic_data_series-acustic_data_series.mean())\n",
    "    freqs = fftpack.fftfreq(len(acustic_data_ft))\n",
    "    pd.DataFrame.from_dict({'acustic_data_ft_amp': np.abs(acustic_data_ft), 'freqs':freqs}).set_index('freqs').plot(ax=axs[2])\n",
    "\n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_angle': np.angle(acustic_data_ft), 'freqs':freqs}).set_index('freqs').plot(ax=axs[3])\n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_angle': np.angle(acustic_data_ft)[1:]+np.angle(acustic_data_ft)[:len(acustic_data_ft)-1], 'freqs':freqs[1:]}).set_index('freqs').plot(ax=axs[3])\n",
    "    pd.DataFrame.from_dict({'acustic_data_ft_angle': np.angle(acustic_data_ft), 'freqs':freqs}).set_index('freqs').rolling(avg_len).mean().plot(ax=axs[3])\n",
    "\n",
    "    pd.DataFrame.from_dict({'acustic_data_ft_real': np.real(acustic_data_ft), 'freqs':freqs}).set_index('freqs').plot(ax=axs[4])\n",
    "\n",
    "    pd.DataFrame.from_dict({'acustic_data_ft_img': np.imag(acustic_data_ft), 'freqs':freqs}).set_index('freqs').plot(ax=axs[5])\n",
    "\n",
    "    #axs[2].stem(freqs, np.abs(acustic_data_ft))\n",
    "    len(acustic_data_ft)\n",
    "    #print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_frame_and_fft, sequence_idx=widgets.IntSlider(min=0,max=df_sample.shape[0]/sequence_length,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.4'></a>\n",
    "## 5.4 Wavelets Transform per Sampling Sequence of 4096 measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index=12 #first training sequence is the shortest one\n",
    "sequence_length = 4096\n",
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "print(df_sample.shape[0]/sequence_length)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fbcotter/pytorch_wavelets\n",
    "\n",
    "[Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution](https://arxiv.org/abs/1904.05049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.signal import cwt\n",
    "from scipy import signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.4.1'></a>\n",
    "### 5.4.1. Continous Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN (Bias) is removed \n",
    "#sequence_idx = 2 #10845\n",
    "avg_len=2\n",
    "sequence_offset = 0\n",
    "def show_frame_and_cwt(sequence_idx):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, sharex=False)\n",
    "\n",
    "    print(df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length].shape)\n",
    "    df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['time_to_failure'].plot(ax=axs[0]);\n",
    "    \n",
    "    acustic_data_series = df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data']\n",
    "    acustic_data_series_zero_mean = (acustic_data_series - acustic_data_series.mean())\n",
    "    acustic_data_series_zero_mean.plot(ax=axs[1])\n",
    "    #df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data'].plot(ax=axs[1]);\n",
    "\n",
    "    fig.set_size_inches(32,4)\n",
    "    \n",
    "    acustic_data_cwt = signal.cwt(acustic_data_series_zero_mean, signal.morlet, #signal.morlet, signal.ricker\n",
    "                                  np.arange(1,31))\n",
    "    axs[2].imshow(acustic_data_cwt, #extent=[-1,1,31,1], \n",
    "                  cmap='PRGn', aspect='auto',  #vmax=abs(acustic_data_series_zero_mean).max(), vmin=-abs(acustic_data_series_zero_mean).max()\n",
    "                 )\n",
    "    #axs[2].stem(freqs, np.abs(acustic_data_ft))\n",
    "    print(len(acustic_data_cwt))\n",
    "    #print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))\n",
    "    print(acustic_data_cwt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "interact(show_frame_and_cwt, sequence_idx=widgets.IntSlider(min=0,max=df_sample.shape[0]/sequence_length,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.4.2'></a>\n",
    "### 5.4.2. Discrete Wavelet Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoise and compress the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multilevel wavelet decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywt import wavedec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN (Bias) is removed \n",
    "#sequence_idx = 2 #10845\n",
    "avg_len=2\n",
    "sequence_offset = 0\n",
    "def show_frame_and_dwt(sequence_idx):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False)\n",
    "\n",
    "    print(df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length].shape)\n",
    "    df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['time_to_failure'].plot(ax=axs[0]);\n",
    "    \n",
    "    acustic_data_series = df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data']\n",
    "    acustic_data_series_zero_mean = (acustic_data_series - acustic_data_series.mean())\n",
    "    acustic_data_series_zero_mean.plot(ax=axs[1])\n",
    "    #df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data'].plot(ax=axs[1]);\n",
    "\n",
    "    fig.set_size_inches(32,4)\n",
    "    \n",
    "    acustic_data_dwt_coeffs = wavedec(acustic_data_series_zero_mean,'db1', level=1)\n",
    "    #acustic_data_cwt = signal.cwt(acustic_data_series_zero_mean, signal.morlet, #signal.morlet, signal.ricker\n",
    "    #                              np.arange(1,31))\n",
    "    #axs[2].imshow(acustic_data_cwt, #extent=[-1,1,31,1], \n",
    "    #              cmap='PRGn', aspect='auto',  #vmax=abs(acustic_data_series_zero_mean).max(), vmin=-abs(acustic_data_series_zero_mean).max()\n",
    "    #             )\n",
    "    #axs[2].stem(freqs, np.abs(acustic_data_ft))\n",
    "    print(len(acustic_data_dwt_coeffs))\n",
    "    print((acustic_data_dwt_coeffs[0]).shape)\n",
    "    #print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))\n",
    "    print(acustic_data_dwt_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_frame_and_dwt, sequence_idx=widgets.IntSlider(min=0,max=df_sample.shape[0]/sequence_length,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the test segment length 150000 samples, what is the required time precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
