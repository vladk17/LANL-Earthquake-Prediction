{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "from os import listdir\n",
    "print(listdir(\"../input\"))\n",
    "\n",
    "import timeit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nrows = !wc -l ../input/train.csv\n",
    "train_nrows_val = int(train_nrows[0].split()[0])\n",
    "print('{:,} rows'.format(train_nrows_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../input/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = !head -n1 ../input/train.csv\n",
    "print(column_names[0].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv', skiprows = 0, nrows=train_nrows_val//100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}) #use chunksize to iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df_with_preset_precision(df, precision):\n",
    "    curr_precision = pd.get_option(\"display.precision\")\n",
    "    pd.set_option(\"display.precision\", precision)\n",
    "    display(df)\n",
    "    pd.set_option(\"display.precision\", curr_precision)\n",
    "display_df_with_preset_precision(df_train.head(), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep minimal mem footprint \n",
    "try:\n",
    "    del(df_train)    \n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_train_iter)    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "df_train_iter = pd.read_csv('../input/train.csv', chunksize=train_nrows_val//100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},iterator=True) #use chunksize to iterate\n",
    "df_after_jump_agg = pd.DataFrame()\n",
    "for df in df_train_iter:\n",
    "    df['diff_in_time_to_failure']=df['time_to_failure'].diff()\n",
    "    df_jumps = df.loc[(df['diff_in_time_to_failure'] > 0)]\n",
    "    #display(df_jumps)\n",
    "    df_after_jump_agg=df_after_jump_agg.append(df_jumps)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_after_jump_agg.shape)\n",
    "df_after_jump_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_train_iter)    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "df_train_iter = pd.read_csv('../input/train.csv', chunksize=train_nrows_val//100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},iterator=True) #use chunksize to iterate\n",
    "df_before_jump_agg = pd.DataFrame()\n",
    "for df in df_train_iter:\n",
    "    if len(df.index.intersection(df_after_jump_agg.index-1)) > 0:\n",
    "        try:\n",
    "            #display(df.loc[df.index.intersection(df_agg.index-1),:])\n",
    "            df_before_jump_agg=df_before_jump_agg.append(df.loc[df.index.intersection(df_after_jump_agg.index-1),:])\n",
    "        except KeyError:\n",
    "            print('KeyError')\n",
    "            pass\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_before_jump_agg.shape)\n",
    "df_before_jump_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ranges = [(ent[0],ent[1]) for ent in zip([0]+list(df_after_jump_agg.index)[:-1],list(df_before_jump_agg.index))]\n",
    "index_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths =np.array([ent[1]-ent[0] for ent in zip([0]+list(df_before_jump_agg.index)[:-1],list(df_before_jump_agg.index))])\n",
    "train_set_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths/train_set_lengths.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index = 3 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "df_sample['acoustic_data'].plot();\n",
    "plt.show()\n",
    "df_sample['time_to_failure'].plot();\n",
    "plt.show()\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 16 train sequences. We may use multiple ways to separate them into train and validation groups. This way we will be able to efficiently utilize the training data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_to_failure_points = pd.read_csv('../input/train.csv', skiprows = 0, nrows= 1, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})['time_to_failure'].append(df_after_jump_agg['time_to_failure'])\n",
    "max_time_to_failure_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_to_failure_points.values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decline_angle_tangents = np.array([ent[0]/ent[1] for ent in zip(max_time_to_failure_points.values[:-1], max_time_to_failure_points.index[1:])])\n",
    "print(decline_angle_tangents.mean())\n",
    "print(decline_angle_tangents.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep minimal mem footprint \n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seg_files = listdir(\"../input/test\")\n",
    "test_seg_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -l ../input/test | wc -l\n",
    "len(test_seg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(\"../input/test\",test_seg_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l {os.path.join(\"../input/test\",test_seg_files[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {os.path.join(\"../input/test\",test_seg_files[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_seg_by_index(idx):\n",
    "    df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[idx]), dtype={'acoustic_data': np.int16})\n",
    "    df_test_seg['acoustic_data'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_test_seg_by_index, idx=widgets.IntSlider(min=0,max=len(test_seg_files)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#all seg files have the same length: 150,000 samples\n",
    "seg_files_lengths = !for filename in ../input/test/*; do wc -l $filename; done\n",
    "{ent.split(' ')[0] for ent in seg_files_lengths}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following:<br>\n",
    "1. simple dot product\n",
    "2. fourier \n",
    "3. wavelets\n",
    "4. voice spectrogrum\n",
    "5. xgb on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index=0 #first training sequence is the shortest one\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "df_sample['acoustic_data'].plot();\n",
    "plt.show()\n",
    "print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))\n",
    "df_sample['time_to_failure'].plot();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['time_to_failure'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to find points of maximum cross-correlation between the segment and the training sequence<br>\n",
    "To save time, the correlation should be calculated efficiently - this means do not implement it by yourself in python. We need to find best implementation of the correlation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[0]), dtype={'acoustic_data': np.int16})\n",
    "df_test_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg['acoustic_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_corr = signal.correlate(df_sample['acoustic_data'].values, df_test_seg['acoustic_data'].values,mode='same', method='fft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(signal_corr).head(100).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = timeit.default_timer()\n",
    "#np_corr = np.correlate(df_sample['acoustic_data'].values, df_test_seg['acoustic_data'].values)\n",
    "#print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))    \n",
    "#this takes too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, t, Sxx = spectrogram(df_test_seg['acoustic_data'].values)\n",
    "#plt.pcolormesh(t, f, Sxx)\n",
    "plt.plot(Sxx)\n",
    "#plt.ylabel('Frequency [Hz]')\n",
    "#plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg['acoustic_data'].values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg['acoustic_data'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].values[0:0+df_test_seg['acoustic_data'].values.shape[0]].dot(df_test_seg['acoustic_data'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "corr_list = [df_sample['acoustic_data'].values[offset:offset+df_test_seg['acoustic_data'].values.shape[0]].dot(df_test_seg['acoustic_data'].values) \\\n",
    "             for offset in range(0,df_sample['acoustic_data'].values.shape[0]-df_test_seg['acoustic_data'].values.shape[0])]\n",
    "print('elapsed time: {} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.abs(corr_list)[-200:]).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg['acoustic_data'].values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_test_seg['acoustic_data'].values).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_offset_of_max = -1\n",
    "max_corr_value = 0\n",
    "for offset in range(0,df_sample['acoustic_data'].values.shape[0]-df_test_seg['acoustic_data'].values.shape[0]):\n",
    "    corr_value = np.abs(df_sample['acoustic_data'].values[offset:offset+df_test_seg['acoustic_data'].values.shape[0]].dot(df_test_seg['acoustic_data'].values))\n",
    "    if np.abs(corr_value) > max_corr_value:\n",
    "        max_corr_value = corr_value\n",
    "        corr_offset_of_max = offset\n",
    "        print('new max_corr_value = {}'.format(max_corr_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(np.stack([df_sample['acoustic_data'].values[:df_test_seg['acoustic_data'].values.shape[0]], df_test_seg['acoustic_data'].values],axis=1)).corr().iloc[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.fft.html <br>\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/fftpack.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_seg['acoustic_data'].values\n",
    "from scipy.fftpack import fft\n",
    "# Number of sample points\n",
    "#N = 600\n",
    "# sample spacing\n",
    "#T = 1.0 / 800.0\n",
    "#x = np.linspace(0.0, N*T, N)\n",
    "#y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n",
    "\n",
    "#yf = fft(y)\n",
    "yf = fft(df_test_seg['acoustic_data'].values)\n",
    "#df_test_seg['acoustic_data'].values\n",
    "\n",
    "#xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "#plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "plt.plot(np.abs(yf))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import cwt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
