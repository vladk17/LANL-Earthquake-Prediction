{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL-Earthquake-Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "* [1. Introduction](#section1)\n",
    "* [2. Initial Setup](#section2)\n",
    "* [3. Training Set EDA](#section3)\n",
    "* [4. Test Set EDA](#section4)\n",
    "* [5. Models](#section5)\n",
    "    * [5.1 Correlations](#section5.1)\n",
    "    * [5.2 Spectrogram](#section5.2)\n",
    "    * [5.3 Fourier Transform per Sampling Sequence of 4096 measurements](#section5.3)\n",
    "    * [5.4 Wavelets Transform per Sampling Sequence of 4096 measurements](#section5.4)\n",
    "        * [5.4.1. Continous Wavelet Transf](#section5.4.1)\n",
    "        * [5.4.2. Discrete Wavelet Transform](#section5.4.2)\n",
    "* [6. Evaluation](#section6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "\n",
    "import timeit\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from scipy import fftpack\n",
    "\n",
    "from os import listdir\n",
    "print(listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. Training Set EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nrows = !wc -l ../input/train.csv\n",
    "train_nrows_val = int(train_nrows[0].split()[0])\n",
    "print('train.csv contains {:,} rows'.format(train_nrows_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../input/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: what is the precision of the ttf in train.csv? See the value of `max_precision` below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "max_precision = 0\n",
    "count = 0\n",
    "with open('../input/train.csv', 'r') as f:\n",
    "    while count<10: #True: #count <10:\n",
    "        line = f.readline()\n",
    "        if not line: \n",
    "            break\n",
    "        else: \n",
    "            #print(line.rstrip())\n",
    "            if count > 0:\n",
    "                #print(line[:-1].split('.')[1])\n",
    "                if '.' in line: \n",
    "                    str_len = len(line[:-1].split('.')[1])\n",
    "                    #print(str_len)\n",
    "                    if max_precision < str_len:\n",
    "                        print(line)\n",
    "                    max_precision = max_precision if max_precision > str_len else str_len\n",
    "#            print(line)\n",
    "#            print(line.split('.')[1])\n",
    "        count +=1\n",
    "print (max_precision)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = !head -n1 ../input/train.csv\n",
    "print(column_names[0].split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sample = pd.read_csv('../input/train.csv', skiprows = 0, nrows=100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64}) #use chunksize to iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df_with_preset_precision(df, precision):\n",
    "    curr_precision = pd.get_option(\"display.precision\")\n",
    "    pd.set_option(\"display.precision\", precision)\n",
    "    display(df)\n",
    "    pd.set_option(\"display.precision\", curr_precision)\n",
    "    \n",
    "display_df_with_preset_precision(df_train_sample.head(9), max_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head ../input/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep minimal mem footprint \n",
    "try:\n",
    "    del(df_train_sample)    \n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: what are the time intervals between the samples?<br>\n",
    "Question: what are the entries where the ttf jumpes up, but not down ? <br>\n",
    "Question: what are the entries where the ttf jumpes down are long, but not down ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "from collections import Counter\n",
    "diff_ttf_2_counter_dict = Counter()\n",
    "try:\n",
    "    del(df_train_iter)    \n",
    "except NameError:\n",
    "    pass\n",
    "#idx = 0\n",
    "df_train_iter = pd.read_csv('../input/train.csv', chunksize=train_nrows_val//100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},iterator=True)\n",
    "time_to_failure_diffs_set = set()\n",
    "df_after_jumping_up_points = pd.DataFrame()\n",
    "df_after_long_jumps_down_points=pd.DataFrame()\n",
    "for df in df_train_iter:\n",
    "    df['diff_in_time_to_failure']=df['time_to_failure'].diff()\n",
    "    nparr_ = df['diff_in_time_to_failure'].values\n",
    "    nparr_ = nparr_[~np.isnan(nparr_)]\n",
    "    diff_ttf_2_counter_dict += Counter(nparr_)\n",
    "\n",
    "#    if idx == 0:\n",
    "#        df_sample_0 = df.copy()\n",
    "#    if idx == 1:\n",
    "#        df_sample_1 = df.copy()        \n",
    "#    idx = idx +1\n",
    "    #time_to_failure_diffs_set = time_to_failure_diffs_set.union(list(set(df['diff_in_time_to_failure'].values)))\n",
    "    #print(set(df['diff_in_time_to_failure'].values[:5]))\n",
    "    df_jumps_up = df.loc[(df['diff_in_time_to_failure'] > 0)]\n",
    "    df_long_jumps_down = df.loc[(df['diff_in_time_to_failure'] < -0.0001)]\n",
    "    #display(df_jumps)\n",
    "    df_after_jumping_up_points=df_after_jumping_up_points.append(df_jumps_up)\n",
    "    df_after_long_jumps_down_points=df_after_long_jumps_down_points.append(df_long_jumps_down)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(diff_ttf_2_counter_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ttf_2_counter_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive jumbs\n",
    "{k: v for k, v in diff_ttf_2_counter_dict.items() if k>0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.**max_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_diff_tff_2_counter_dict = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in diff_ttf_2_counter_dict.items():\n",
    "    if k<=0:\n",
    "        negative_diff_tff_2_counter_dict[int(-k*(10.**max_precision))] += v \n",
    "negative_diff_tff_2_counter_dict     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time diff within sampling frames\n",
    "time_diff_within_sampling_frames_2_count_dict = {k: v for k, v in negative_diff_tff_2_counter_dict.items() if k<100}\n",
    "time_diff_within_sampling_frames_2_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time diff between sampling frames\n",
    "time_diff_between_sampling_frames_2_count_dict = {round(k/(10.**max_precision),6): v for k, v in negative_diff_tff_2_counter_dict.items() if k>=100}\n",
    "time_diff_between_sampling_frames_2_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_after_jumping_up_points.shape)\n",
    "display_df_with_preset_precision(df_after_jumping_up_points, max_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df_with_preset_precision(df_after_long_jumps_down_points.head(),max_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: what are the lengths of sampling frames (the numbers of samples between long jups down)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.diff(df_after_long_jumps_down_points.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.diff(df_after_long_jumps_down_points.index)==8192)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.diff(df_after_long_jumps_down_points.index)==4095)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(np.diff(df_after_long_jumps_down_points.index)==4096)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(time_diff_within_sampling_frames_2_count_dict.keys())/(10.**max_precision)*8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(time_diff_between_sampling_frames_2_count_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: what is the relation between the time length of the longest (8192 samples) samplling frame and the average time distance (0.001) between the sampling frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max(time_diff_within_sampling_frames_2_count_dict.keys())/(10.**max_precision)*8192)/np.mean(list(time_diff_between_sampling_frames_2_count_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_train_iter)    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "df_train_iter = pd.read_csv('../input/train.csv', chunksize=train_nrows_val//100,\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64},iterator=True) #use chunksize to iterate\n",
    "df_before_jumping_up_points = pd.DataFrame()\n",
    "for df in df_train_iter:\n",
    "    if len(df.index.intersection(df_after_jumping_up_points.index-1)) > 0:\n",
    "        try:\n",
    "            df_before_jumping_up_points=df_before_jumping_up_points.append(df.loc[df.index.intersection(df_after_jumping_up_points.index-1),:])\n",
    "        except KeyError:\n",
    "            print('KeyError')\n",
    "            pass\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_before_jumping_up_points.shape)\n",
    "df_before_jumping_up_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "try:\n",
    "    del(df_train_tail)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_train_tail = pd.read_csv('../input/train.csv', skiprows = train_nrows_val-100000, iterator=False, names=column_names[0].split(','))\n",
    "df_train_tail['acoustic_data'] = df_train_tail['acoustic_data'].astype(np.int16)\n",
    "df_train_tail['time_to_failure'] = df_train_tail['time_to_failure'].astype(np.float64)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tail.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps in ttf:\n",
    "#ttf steps width is 4097 for the last section:\n",
    "#df_train_tail.tail(4097)['time_to_failure'].plot();\n",
    "df_train_tail.tail(20000)['time_to_failure'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "try:\n",
    "    del(df_train_head)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_train_head = pd.read_csv('../input/train.csv', skiprows = 0, nrows = 100000, iterator=False)\n",
    "\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttf steps width is 4096 for the first section:\n",
    "#df_train_head.head(4096)['time_to_failure'].plot();\n",
    "#df_train_head.head(20000)['time_to_failure'].plot();\n",
    "\n",
    "df_train_head.head(20000)[8192:8192+4096]['time_to_failure'].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_train_head.head(20000)[8192:8192+4095]['time_to_failure'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "set(df_train_head.head(2000000)['time_to_failure'].diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What these steps in ttf mean? <br>\n",
    "Options: \n",
    "* 1. we are given not continuos in time sequencies (each ~4096 samples) of acustic data. \n",
    "* 2. the sequences of the acustic data are continuous in time but ttf represent changing steps/jumps/phases in the state of the material\n",
    "\n",
    "The first option is more probable as it is unlikely that the changes in the phase states of the material will take place with such ideal periodicity. Then, time/frequency characteristics of the acustic_data should be considered taking into acount that the data is not continous in time. \n",
    "\n",
    "We assume that samples of the signal are taken each $10^{-3}$ time units (sec?/usec?) and each sample is a sequence of 4096 measurements taken each $10^{-9}$ time units. So, the length of the entire signal sample is $4.096\\times10^{-6}$ time units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ranges = [(ent[0],ent[1]) for ent in zip([0]+list(df_after_jumping_up_points.index)[:-1],list(df_before_jumping_up_points.index))]\n",
    "index_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths =np.array([ent[1]-ent[0] for ent in zip([0]+list(df_before_jumping_up_points.index)[:-1],list(df_before_jumping_up_points.index))])\n",
    "train_set_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_lengths.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index = 3 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 15000\n",
    "window_offset = -window_size\n",
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "print(df_sample.index)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False)\n",
    "fig.set_size_inches(32,4)\n",
    "df_sample['acoustic_data'].plot(ax=axs[0]);\n",
    "#plt.show()\n",
    "df_sample['time_to_failure'].plot(ax=axs[1]);\n",
    "#plt.show()\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 16 train sequences. We may use multiple ways to separate them into train and validation groups. This way we will be able to efficiently utilize the training data we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_to_failure_points = pd.read_csv('../input/train.csv', skiprows = 0, nrows= 1, dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})['time_to_failure'].append(df_after_jumping_up_points['time_to_failure'])\n",
    "max_time_to_failure_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time_to_failure_points.values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decline_angle_tangents = np.array([ent[0]/ent[1] for ent in zip(max_time_to_failure_points.values[:-1], max_time_to_failure_points.index[1:])])\n",
    "print(decline_angle_tangents.mean())\n",
    "print(decline_angle_tangents.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep minimal mem footprint \n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## 4. Test Set EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seg_files = listdir(\"../input/test\")\n",
    "test_seg_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls -l ../input/test | wc -l\n",
    "len(test_seg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(\"../input/test\",test_seg_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l {os.path.join(\"../input/test\",test_seg_files[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {os.path.join(\"../input/test\",test_seg_files[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_seg_by_index(idx):\n",
    "    df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[idx]), dtype={'acoustic_data': np.int16})\n",
    "    (df_test_seg['acoustic_data']-df_test_seg['acoustic_data'].mean()).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(plot_test_seg_by_index, idx=widgets.IntSlider(min=0,max=len(test_seg_files)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make sure that all seg files have the same length: 150,000 samples:\n",
    "seg_files_lengths = !for filename in ../input/test/*; do wc -l $filename; done\n",
    "{ent.split(' ')[0] for ent in seg_files_lengths}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time length of a test segment defines meaninful precision of the predicted ttf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: assuming that each test segment contains samples without long jumps after each 4096 samples, what is the time length of the test segment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(max(time_diff_within_sampling_frames_2_count_dict.keys())/(10.**max_precision)*150000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: assuming that the test segments contain long jupmps after each 4096 samples, what is the time length of the test segment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(time_diff_between_sampling_frames_2_count_dict.keys()))*(150000/4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## 5. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the following:\n",
    "* 0. collect features per sampling frame (4095, 4096, 8192 samples)\n",
    "* 1. investigate train sequences in parallel with window of variable size:  15000 or smaller\n",
    "    * 1.1 normalize to the same process development speed; (with_time_to_failure plots)\n",
    "    * 1.2 present the acustic_data in a form of mean plus delta from mean, then delta from mean present by its mean and delta from its mean etc. \n",
    "* 2. remove constant bias in train and in test\n",
    "* 3. simple MSE alignment \n",
    "* 4. simple maximaize dot product\n",
    "* 5. fourier (fft)\n",
    "    * 5.1 look at differences in fourier coefficients between the sampling frames\n",
    "* 6. short-time fourier (time frequency domain)\n",
    "* 7. wavelets (time frequency domain)\n",
    "    * 7.1. cwt and dwt\n",
    "    * 7.2. Haar (rectangular) and Morlet wavelets\n",
    "* 8. voice spectrogrum; what is we are already given a spectorgrum (or other type of transform) but not the original signal? \n",
    "* 9. try to use notebooks used for the detection of gravitation waves\n",
    "* 10. xgboost\n",
    "* 11. try to extract a \"coherent\" signal and to remove the noise in the training data sequences \n",
    "* 12. set evaluation criterion\n",
    "* 13. try to accelerate the process using pytorch (on gpu) for matrix and vector operations\n",
    "* 14. try Fully Connected NN\n",
    "* 14. try CNNs on 64 x 64 images based on 4096 samples frames\n",
    "* 15. try RNNs/LSTMs\n",
    "* 16. try exponential or other smoothing to reduce noise \n",
    "* 17. try considering 4096 samples as 64 x 64 image\n",
    "* 18. try averaging over all 16 training sequences - (in time or frequencey space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.1'></a>\n",
    "### 5.1. Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "range_index=0 #first training sequence is the shortest one\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False)\n",
    "fig.set_size_inches(32,4)\n",
    "df_sample['acoustic_data'].plot(ax=axs[0]);\n",
    "#plt.show()\n",
    "print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))\n",
    "df_sample['time_to_failure'].plot(ax=axs[1]);\n",
    "#plt.show()\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['time_to_failure'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to find points of maximum cross-correlation between the segment and the training sequence<br>\n",
    "To save time, the correlation should be calculated efficiently - this means do not implement it by yourself in python. We need to find best implementation of the correlation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['acoustic_data'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = (df_sample['acoustic_data']-df_sample['acoustic_data'].mean()).values\n",
    "train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[0]), dtype={'acoustic_data': np.int16})\n",
    "df_test_seg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_seg['acoustic_data'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = (df_test_seg['acoustic_data']-df_test_seg['acoustic_data'].mean()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_corr = signal.correlate(np.square(train_values), np.square(test_values),mode='valid', #full, valid, same\n",
    "                               method='fft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(signal_corr).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_with_test_seg_idx(idx):\n",
    "    df_test_seg = pd.read_csv(os.path.join(\"../input/test\",test_seg_files[idx]), dtype={'acoustic_data': np.int16})\n",
    "    test_values = (df_test_seg['acoustic_data']-df_test_seg['acoustic_data'].mean()).values\n",
    "    signal_corr = signal.correlate(np.square(train_values), np.square(test_values),mode='same', method='fft')\n",
    "    pd.DataFrame(signal_corr).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(correlation_with_test_seg_idx, idx=widgets.IntSlider(min=0,max=len(test_seg_files)-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = timeit.default_timer()\n",
    "#np_corr = np.correlate(df_sample['acoustic_data'].values, df_test_seg['acoustic_data'].values)\n",
    "#print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))    \n",
    "#this takes too long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.2'></a>\n",
    "### 5.2 Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 1024\n",
    "N = 1024\n",
    "freqs, times, Sx = signal.spectrogram(df_test_seg['acoustic_data'].values, fs=1, window='hanning',\n",
    "                                      nperseg=N, noverlap=M - 100,\n",
    "                                      detrend=False, scaling='spectrum')\n",
    "\n",
    "f, ax = plt.subplots(figsize=(4.8, 2.4))\n",
    "ax.pcolormesh(times, freqs / 1000, 10 * np.log10(Sx), cmap='viridis')\n",
    "ax.set_ylabel('Frequency [kHz]')\n",
    "ax.set_xlabel('Time [s]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, t, Sxx = spectrogram(df_test_seg['acoustic_data'].values)\n",
    "plt.pcolormesh(t, f, 10 * np.log10(Sxx))\n",
    "plt.show()\n",
    "plt.plot(Sxx)\n",
    "#plt.ylabel('Frequency [Hz]')\n",
    "#plt.xlabel('Time [sec]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util\n",
    "\n",
    "M = 1024\n",
    "\n",
    "slices = util.view_as_windows(df_test_seg['acoustic_data'].values, window_shape=(M,), step=100)\n",
    "print(f'data shape: {df_test_seg[\"acoustic_data\"].values.shape}, Sliced data shape: {slices.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = np.hanning(M + 1)[:-1]\n",
    "slices = slices * win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = slices.T\n",
    "print('Shape of `slices`:', slices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum = np.fft.fft(slices, axis=0)[:M // 2 + 1:-1]\n",
    "spectrum = np.abs(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=df_test_seg['acoustic_data'].values.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(4.8, 2.4))\n",
    "\n",
    "S = np.abs(spectrum)\n",
    "S = 20 * np.log10(S / np.max(S))\n",
    "\n",
    "ax.imshow(S, origin='lower', cmap='viridis',\n",
    "          extent=(0, L, 0, rate / 2 / 1000))\n",
    "ax.axis('tight')\n",
    "ax.set_ylabel('Frequency [kHz]')\n",
    "ax.set_xlabel('Time [s]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_seg['acoustic_data'].values\n",
    "# Number of sample points\n",
    "#N = 600\n",
    "# sample spacing\n",
    "#T = 1.0 / 800.0\n",
    "#x = np.linspace(0.0, N*T, N)\n",
    "#y = np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(80.0 * 2.0*np.pi*x)\n",
    "\n",
    "#yf = fft(y)\n",
    "yf = fftpack.fft(df_test_seg['acoustic_data'].values)\n",
    "#df_test_seg['acoustic_data'].values\n",
    "\n",
    "#xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "\n",
    "#plt.plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "plt.plot(np.abs(yf))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.3'></a>\n",
    "## 5.3 Fourier Transform per Sampling Sequence of 4096 measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.fft.html <br>\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/fftpack.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df_with_preset_precision(df_after_long_jumps_down_points.head(),max_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index=12 #first training sequence is the shortest one\n",
    "#sequence_length = 4096\n",
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "#print(df_sample.shape[0]/sequence_length)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_df_with_preset_precision(df_sample.head(),max_precision)\n",
    "df_sample.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_ranges[range_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ixs_of_indexes = np.where(np.all([df_after_long_jumps_down_points.index <= index_ranges[range_index][1],df_after_long_jumps_down_points.index >= index_ranges[range_index][0]-1],axis=0))[0]\n",
    "ixs_of_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixs_of_indexes1 = np.where(np.logical_and(df_after_long_jumps_down_points.index <= index_ranges[range_index][1],\n",
    "                        df_after_long_jumps_down_points.index >= index_ranges[range_index][0]))[0]\n",
    "ixs_of_indexes1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(ixs_of_indexes1,ixs_of_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = df_after_long_jumps_down_points.index[ixs_of_indexes].union(index_ranges[range_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.diff(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_indexes = list(zip(indexes[:-1],indexes[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(frame_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD: work with resolution of a sampling frame <br>\n",
    "for each sampling frame:\n",
    "* TBD: calculate the average ttf - the label\n",
    "* TBD: check what is the time difference between near samples - check if we can find any pattern\n",
    "* TBD: take an average amplitude of the signal \n",
    "* TBD: get fft \n",
    "* TBD: get rfft \n",
    "* TBD: get differences between fft coefficients between consequent frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN (Bias) is removed \n",
    "low_path_filter_n_freqs = 1024\n",
    "avg_len=1\n",
    "frame_sequence_offset = -frame_indexes[0][0]\n",
    "def show_frame_and_fft(sequence_idx):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, sharex=False)\n",
    "\n",
    "    #print(df_sample[frame_sequence_offset+sequence_length*sequence_idx:frame_sequence_offset+sequence_length*sequence_idx+sequence_length].shape)\n",
    "    the_df = df_sample[frame_sequence_offset+frame_indexes[sequence_idx][0]:frame_sequence_offset+frame_indexes[sequence_idx][1]]\n",
    "    print(the_df.shape)\n",
    "    #df_sample[frame_sequence_offset+sequence_length*sequence_idx:frame_sequence_offset+sequence_length*sequence_idx+sequence_length]['time_to_failure'].plot(ax=axs[0]);\n",
    "    #the_df['time_to_failure'].plot(ax=axs[0]);\n",
    "    diff_ttf = the_df['time_to_failure'].diff()[1:]\n",
    "    \n",
    "    #acustic_data_series = df_sample[frame_sequence_offset+sequence_length*sequence_idx:frame_sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data']\n",
    "    acustic_data_series = the_df['acoustic_data']\n",
    "    \n",
    "    print('ttf = {:.9f}'.format(the_df['time_to_failure'].mean()))\n",
    "    print('diff_ttf.mean = {:.9f}, diff_ttf.std = {:.9f}'.format(diff_ttf.mean(), diff_ttf.std()))\n",
    "    print('acustic.mean = {:.9f}, acustic.std = {:.9f}'.format(acustic_data_series.mean(), acustic_data_series.std()))\n",
    "    \n",
    "    (acustic_data_series - acustic_data_series.mean()).plot(ax=axs[0]);\n",
    "    #df_sample[frame_sequence_offset+sequence_length*sequence_idx:frame_sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data'].plot(ax=axs[1]);\n",
    "\n",
    "    fig.set_size_inches(32,4)\n",
    "    \n",
    "    acustic_data_rft = fftpack.rfft(acustic_data_series-acustic_data_series.mean())\n",
    "    acustic_data_ft = fftpack.fft(acustic_data_series-acustic_data_series.mean())\n",
    "    \n",
    "    rfreqs = fftpack.rfftfreq(acustic_data_rft.size,diff_ttf.mean())\n",
    "    freqs = fftpack.fftfreq(acustic_data_ft.size, diff_ttf.mean())\n",
    "    \n",
    "    \n",
    "    #freqs = freqs/(diff_ttf.mean()*the_df.shape[0])\n",
    "    rfreqs = -rfreqs\n",
    "    \n",
    "    the_dict = {}\n",
    "    for idx in range(len(acustic_data_rft)):\n",
    "        if rfreqs[idx] in the_dict:\n",
    "            the_dict[rfreqs[idx]] = (the_dict[rfreqs[idx]]+np.abs(acustic_data_rft[idx]))/2.\n",
    "        else: \n",
    "            the_dict[rfreqs[idx]] = np.abs(acustic_data_rft[idx])\n",
    "    unique_rfreqs = np.unique(rfreqs)\n",
    "    print(\"arrays are equal is {}\".format(np.array_equal(sorted(unique_rfreqs),unique_rfreqs)))\n",
    "    \n",
    "    #print(len(rfreqs[:]))\n",
    "    #print(type(rfreqs[:]))\n",
    "    #print(len(np.unique(rfreqs[:])))\n",
    "    #print(freqs[len(freqs)//2:])\n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_amp': np.abs(acustic_data_ft)[len(freqs)//2:], 'freqs':freqs[len(freqs)//2:]}).set_index('freqs').plot(ax=axs[2])\n",
    "    #pd.DataFrame.from_dict({'acustic_data_rft_amp': [the_dict[ent] for ent in unique_rfreqs], 'rfreqs':unique_rfreqs}).set_index('rfreqs').plot(ax=axs[1])\n",
    "    pd.DataFrame.from_dict({'acustic_data_rft_amp': [the_dict[ent] for ent in unique_rfreqs][:low_path_filter_n_freqs], \n",
    "                            'rfreqs':unique_rfreqs[:low_path_filter_n_freqs]}).set_index('rfreqs').plot(ax=axs[1])\n",
    "    #pd.DataFrame.from_dict({'acustic_data_rft_amp': np.abs(acustic_data_rft), 'rfreqs':rfreqs}).set_index('rfreqs').plot(ax=axs[1])\n",
    "    pd.DataFrame.from_dict({'acustic_data_ft_amp': (np.abs(acustic_data_ft)[len(freqs)//2:]), \n",
    "                            'freqs':freqs[len(freqs)//2:]}).set_index('freqs').plot(ax=axs[2])\n",
    "\n",
    "    \n",
    "    \n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_angle': np.angle(acustic_data_ft), 'freqs':freqs}).set_index('freqs').plot(ax=axs[3])\n",
    "    #pd.DataFrame.from_dict({'acustic_data_rft_angle': np.angle(acustic_data_rft), 'rfreqs':rfreqs}).set_index('rfreqs').plot(ax=axs[3])\n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_angle': np.angle(acustic_data_ft)[1:]+np.angle(acustic_data_ft)[:len(acustic_data_ft)-1], 'freqs':freqs[1:]}).set_index('freqs').plot(ax=axs[3])\n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_angle': np.angle(acustic_data_ft), 'freqs':freqs}).set_index('freqs').rolling(avg_len).mean().plot(ax=axs[3])\n",
    "\n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_real': np.real(acustic_data_ft), 'freqs':freqs}).set_index('freqs').plot(ax=axs[4])\n",
    "\n",
    "    #pd.DataFrame.from_dict({'acustic_data_ft_img': np.imag(acustic_data_ft), 'freqs':freqs}).set_index('freqs').plot(ax=axs[5])\n",
    "\n",
    "    #axs[2].stem(freqs, np.abs(acustic_data_ft))\n",
    "    #len(acustic_data_rft)\n",
    "    #print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('range_index = {}'.format(range_index))\n",
    "interact(show_frame_and_fft, sequence_idx=widgets.IntSlider(min=0,max=len(list(frame_indexes))-1,step=1,value=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fft_amp_per_sequence_index(sequence_idx):\n",
    "    the_df = df_sample[frame_sequence_offset+frame_indexes[sequence_idx][0]:frame_sequence_offset+frame_indexes[sequence_idx][1]]\n",
    "\n",
    "    diff_ttf = the_df['time_to_failure'].diff()[1:]   \n",
    "    acustic_data_series = the_df['acoustic_data']\n",
    "    \n",
    "    print('ttf = {:.9f}'.format(the_df['time_to_failure'].mean()))\n",
    "    print('diff_ttf.mean = {:.9f}, diff_ttf.std = {:.9f}'.format(diff_ttf.mean(), diff_ttf.std()))\n",
    "    print('acustic.mean = {:.9f}, acustic.std = {:.9f}'.format(acustic_data_series.mean(), acustic_data_series.std()))    \n",
    "    \n",
    "    acustic_data_rft = fftpack.rfft(acustic_data_series-acustic_data_series.mean())\n",
    "       \n",
    "    rfreqs = -fftpack.rfftfreq(len(acustic_data_rft),diff_ttf.mean())   \n",
    "    \n",
    "    the_dict = {}\n",
    "    for idx in range(len(acustic_data_rft)):\n",
    "        if rfreqs[idx] in the_dict:\n",
    "            the_dict[rfreqs[idx]] = (the_dict[rfreqs[idx]]+np.abs(acustic_data_rft[idx]))/2.\n",
    "        else: \n",
    "            the_dict[rfreqs[idx]] = np.abs(acustic_data_rft[idx])\n",
    "    \n",
    "    unique_rfreqs = np.unique(rfreqs)\n",
    "    \n",
    "    return pd.DataFrame.from_dict({'acustic_data_rft_amp': [the_dict[ent] for ent in unique_rfreqs][:low_path_filter_n_freqs], \n",
    "                                   'rfreqs':unique_rfreqs[:low_path_filter_n_freqs]}).set_index('rfreqs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(calc_fft_amp_per_sequence_index(0)['acustic_data_rft_amp']).values[:low_path_filter_n_freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_row_per_sequence_index(sequence_idx):\n",
    "    the_df = df_sample[frame_sequence_offset+frame_indexes[sequence_idx][0]:frame_sequence_offset+frame_indexes[sequence_idx][1]]\n",
    "\n",
    "    diff_ttf = the_df['time_to_failure'].diff()[1:]   \n",
    "    acustic_data_series = the_df['acoustic_data']\n",
    "    \n",
    "    #print('ttf = {:.9f}'.format(the_df['time_to_failure'].mean()))\n",
    "    #print('diff_ttf.mean = {:.9f}, diff_ttf.std = {:.9f}'.format(diff_ttf.mean(), diff_ttf.std()))\n",
    "    #print('acustic.mean = {:.9f}, acustic.std = {:.9f}'.format(acustic_data_series.mean(), acustic_data_series.std()))    \n",
    "    \n",
    "    acustic_data_rft = fftpack.rfft(acustic_data_series-acustic_data_series.mean())\n",
    "       \n",
    "    rfreqs = -fftpack.rfftfreq(len(acustic_data_rft),diff_ttf.mean())   \n",
    "    \n",
    "    the_dict = {}\n",
    "    for idx in range(len(acustic_data_rft)):\n",
    "        if rfreqs[idx] in the_dict:\n",
    "            the_dict[rfreqs[idx]] = (the_dict[rfreqs[idx]]+np.abs(acustic_data_rft[idx]))/2.\n",
    "        else: \n",
    "            the_dict[rfreqs[idx]] = np.abs(acustic_data_rft[idx])\n",
    "    \n",
    "    unique_rfreqs = np.unique(rfreqs)\n",
    "    \n",
    "    return [acustic_data_series.mean()]+[the_dict[ent] for ent in unique_rfreqs][:low_path_filter_n_freqs][1:]+[the_df['time_to_failure'].mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features_row_per_sequence_index(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.4'></a>\n",
    "## 5.4 Wavelets Transform per Sampling Sequence of 4096 measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_index=12 #first training sequence is the shortest one\n",
    "sequence_length = 4096\n",
    "start_time = timeit.default_timer()\n",
    "try:\n",
    "    del(df_sample)    \n",
    "except NameError:\n",
    "    pass\n",
    "df_sample = pd.read_csv('../input/train.csv', skiprows = index_ranges[range_index][0], nrows= index_ranges[range_index][1]-index_ranges[range_index][0],\n",
    "                       dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n",
    "df_sample.columns=['acoustic_data','time_to_failure']\n",
    "print(df_sample.shape[0]/sequence_length)\n",
    "print('elapsed time: {:.2f} sec'.format(timeit.default_timer()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fbcotter/pytorch_wavelets\n",
    "\n",
    "[Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution](https://arxiv.org/abs/1904.05049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.signal import cwt\n",
    "from scipy import signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.4.1'></a>\n",
    "### 5.4.1. Continous Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN (Bias) is removed \n",
    "#sequence_idx = 2 #10845\n",
    "avg_len=2\n",
    "sequence_offset = 0\n",
    "def show_frame_and_cwt(sequence_idx):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, sharex=False)\n",
    "\n",
    "    print(df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length].shape)\n",
    "    df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['time_to_failure'].plot(ax=axs[0]);\n",
    "    \n",
    "    acustic_data_series = df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data']\n",
    "    acustic_data_series_zero_mean = (acustic_data_series - acustic_data_series.mean())\n",
    "    acustic_data_series_zero_mean.plot(ax=axs[1])\n",
    "    #df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data'].plot(ax=axs[1]);\n",
    "\n",
    "    fig.set_size_inches(32,4)\n",
    "    \n",
    "    acustic_data_cwt = signal.cwt(acustic_data_series_zero_mean, signal.morlet, #signal.morlet, signal.ricker\n",
    "                                  np.arange(1,31))\n",
    "    axs[2].imshow(acustic_data_cwt, #extent=[-1,1,31,1], \n",
    "                  cmap='PRGn', aspect='auto',  #vmax=abs(acustic_data_series_zero_mean).max(), vmin=-abs(acustic_data_series_zero_mean).max()\n",
    "                 )\n",
    "    #axs[2].stem(freqs, np.abs(acustic_data_ft))\n",
    "    print(len(acustic_data_cwt))\n",
    "    #print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))\n",
    "    print(acustic_data_cwt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(show_frame_and_cwt, sequence_idx=widgets.IntSlider(min=0,max=df_sample.shape[0]/sequence_length,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5.4.2'></a>\n",
    "### 5.4.2. Discrete Wavelet Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoise and compress the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multilevel wavelet decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pywt import wavedec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEAN (Bias) is removed \n",
    "#sequence_idx = 2 #10845\n",
    "avg_len=2\n",
    "sequence_offset = 0\n",
    "def show_frame_and_dwt(sequence_idx):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, sharex=False)\n",
    "\n",
    "    print(df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length].shape)\n",
    "    df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['time_to_failure'].plot(ax=axs[0]);\n",
    "    \n",
    "    acustic_data_series = df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data']\n",
    "    acustic_data_series_zero_mean = (acustic_data_series - acustic_data_series.mean())\n",
    "    acustic_data_series_zero_mean.plot(ax=axs[1])\n",
    "    #df_sample[sequence_offset+sequence_length*sequence_idx:sequence_offset+sequence_length*sequence_idx+sequence_length]['acoustic_data'].plot(ax=axs[1]);\n",
    "\n",
    "    fig.set_size_inches(32,4)\n",
    "    \n",
    "    acustic_data_dwt_coeffs = wavedec(acustic_data_series_zero_mean,'db1', level=1)\n",
    "    #acustic_data_cwt = signal.cwt(acustic_data_series_zero_mean, signal.morlet, #signal.morlet, signal.ricker\n",
    "    #                              np.arange(1,31))\n",
    "    #axs[2].imshow(acustic_data_cwt, #extent=[-1,1,31,1], \n",
    "    #              cmap='PRGn', aspect='auto',  #vmax=abs(acustic_data_series_zero_mean).max(), vmin=-abs(acustic_data_series_zero_mean).max()\n",
    "    #             )\n",
    "    #axs[2].stem(freqs, np.abs(acustic_data_ft))\n",
    "    print(len(acustic_data_dwt_coeffs))\n",
    "    print((acustic_data_dwt_coeffs[0]).shape)\n",
    "    #print ('time_to_failure decline rate = {:.16f}'.format(df_sample['time_to_failure'][0]/df_sample['time_to_failure'].shape[0]))\n",
    "    print(acustic_data_dwt_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact(show_frame_and_dwt, sequence_idx=widgets.IntSlider(min=0,max=df_sample.shape[0]/sequence_length,step=1,value=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the test segment length 150000 samples, what is the required time precision?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
